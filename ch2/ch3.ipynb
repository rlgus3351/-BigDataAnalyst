{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c50ca28",
   "metadata": {},
   "source": [
    "# 머신러닝 평가지표\n",
    "- section 1 : 이진 분류 평가지표\n",
    "- section 2 : 다중 분류 평가지표\n",
    "- section 3 : 회귀 평가지표"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4addd683",
   "metadata": {},
   "source": [
    "## Section.1 이진 분류 평가지표\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06aaf364",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "y_true = pd.DataFrame([1,1,1,0,0,1,1,1,1,0])\n",
    "y_pred = pd.DataFrame([1,0,1,1,0,0,0,1,1,0])\n",
    "\n",
    "y_true_str = pd.DataFrame(['A','A','A','B','B','A','A','A','A','B'])\n",
    "y_pred_str = pd.DataFrame(['A','B','A','A','B','B','B','A','A','B'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196700cd",
   "metadata": {},
   "source": [
    "### 정확도\n",
    "- 정확도는 전체 데이터 중에서 올바르게 예측된 데이터의 비율을 나타낸다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1dba0b93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도 : 0.6\n",
      "정확도 : 0.6\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "print(\"정확도 :\", accuracy)\n",
    "\n",
    "accuracy = accuracy_score(y_true_str,y_pred_str)\n",
    "print(\"정확도 :\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d54def56",
   "metadata": {},
   "source": [
    "### 정밀도\n",
    "- 정밀도는 양성으로 예측된 데이터 중 실제로 양성인 비율을 나타낸다.\n",
    "- 모델이 양성이라고 예측한 경우 얼마나 정확하게 예측했는지를 평가하는 지표이다.\n",
    "- 문자 형태의 target을 사용할 떄는 pos_label='A'와 같이 양성 클래스를 명시해야한다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54e5536a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정밀도 :  0.8\n",
      "정밀도 :  0.8\n"
     ]
    }
   ],
   "source": [
    "#정밀도\n",
    "from sklearn.metrics import precision_score\n",
    "precision = precision_score(y_true, y_pred)\n",
    "print(\"정밀도 : \",precision)\n",
    "\n",
    "precision = precision_score(y_true_str, y_pred_str, pos_label='A')\n",
    "\n",
    "print(\"정밀도 : \",precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e13bf39",
   "metadata": {},
   "source": [
    "### 재현율\n",
    "- 재현율은 실제 양성인 데이터 중 모델이 양성으로 올바르게 예측한 비율을 나타냄.\n",
    "- 문자 형태의 경우 양성 클래스 지정이 필요하다.\n",
    "- 결과는 1에 가까울 수록 좋다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3777a22e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall :  0.5714285714285714\n",
      "recall :  0.5714285714285714\n"
     ]
    }
   ],
   "source": [
    "# 재현율\n",
    "from sklearn.metrics import recall_score\n",
    "recall = recall_score(y_true, y_pred)\n",
    "print(\"recall : \",recall)\n",
    "\n",
    "recall = recall_score(y_true_str, y_pred_str, pos_label='A')\n",
    "print(\"recall : \",recall)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1854ae",
   "metadata": {},
   "source": [
    "### F1 스코어\n",
    "- f1 score는 정밀도와 재현율의 조화 평균을 나타낸다.\n",
    "- 불균형 데이터를 평가하는데 유용하다.\n",
    "- 문자 형태의 경우 양성 클래스 지정이 필요\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "311302fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1스코어 :  0.6666666666666666\n",
      "f1 스코어 :  0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "print(\"f1스코어 : \", f1)\n",
    "\n",
    "\n",
    "f1 = f1_score(y_true_str, y_pred_str, pos_label='A')\n",
    "print(\"f1 스코어 : \",f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2bfb97",
   "metadata": {},
   "source": [
    "### ROC-AUC\n",
    "- ROC 곡선 아래 영역 , 즉 AUC는 모델의 분류 성능을 평가하는 지표다.\n",
    "- 양성 클래스에 속할 확률을 예측하기 위해 모델에 predict_proba()를 사용한다.\n",
    "- predict_proba()는 각 클래스에 속할 확률을 반환\n",
    "- 양성 클래스에 대한 확률을 분석하기 위해 반환된 배열의 두 번째 열(pred[:,1])의 값을 사용하낟.\n",
    "- 1에 가까울 수록 모델의 성능이 우수함을 의미한다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee876150",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC_AUC 0.86\n"
     ]
    }
   ],
   "source": [
    "# ROU-AUC\n",
    "from sklearn.metrics import roc_auc_score\n",
    "y_true = pd.DataFrame([0,1,0,1,1,0,0,0,1,1])\n",
    "y_pred_proba = pd.DataFrame([0.4,0.9,0.1,0.3,0.8,0.6,0.4,0.2,0.7,0.6])\n",
    "\n",
    "\n",
    "roc_auc = roc_auc_score(y_true, y_pred_proba)\n",
    "print(\"ROC_AUC\", roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be14017",
   "metadata": {},
   "source": [
    "## Section.2 다중 분류 평가지표\n",
    "- 다중 분류 평가지표는 이진 분류 평가지표와 유사하다.\n",
    "- 다중 분류로 평가하기 위해 정밀도, 재현율, F1스코어는 평균을 계산하는 방식이 필요\n",
    "    - Macro 평균 : 각 클래스에 대한 정밀도/재현률/F1 점수의 평균을 계산\n",
    "    - Micro 평균 : 모든 클래스에 대한 전체적인 정밀도/재현률/F1 점수를 계산\n",
    "    - Weighted 평균 : 각 클래스에 대한 정밀도/재현률/F1 점수의 가중 평균을 계산\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5eb18ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = pd.DataFrame([1,2,3,3,2,1,3,3,2,1])\n",
    "y_pred = pd.DataFrame([1,2,1,3,2,1,1,2,2,1])\n",
    "\n",
    "y_true_str = pd.DataFrame(['A','B','C','C','B','A','C','C','B','A'])\n",
    "y_pred_str = pd.DataFrame(['A','B','A','C','B','A','A','B','B','A'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e438a8a4",
   "metadata": {},
   "source": [
    "### 정확도\n",
    "- 정확도는 이진분류와 평가 방법은 동일\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0455214f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  0.7\n",
      "Accuracy :  0.7\n"
     ]
    }
   ],
   "source": [
    "# 정확도 \n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "print(\"Accuracy : \",accuracy)\n",
    "\n",
    "accuracy = accuracy_score(y_true_str, y_pred_str)\n",
    "print(\"Accuracy : \",accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de89d33",
   "metadata": {},
   "source": [
    "### 정밀도\n",
    "- average는 micro, macro, weighted중 문제에서 요구하는 방식을 선택한다.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a02aa0b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정밀도 :  0.7833333333333333\n",
      "정밀도 :  0.7833333333333333\n"
     ]
    }
   ],
   "source": [
    "# 정밀도(Precision)\n",
    "from sklearn.metrics import precision_score\n",
    "precision = precision_score(y_true, y_pred, average='macro')\n",
    "print(\"정밀도 : \", precision)\n",
    "\n",
    "precision = precision_score(y_true_str, y_pred_str, average='macro')\n",
    "print(\"정밀도 : \", precision)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6bf6b0",
   "metadata": {},
   "source": [
    "### 재현율\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1bd341cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "재현율 :  0.75\n",
      "재현율 :  0.75\n"
     ]
    }
   ],
   "source": [
    "# 재현율(recall)\n",
    "from sklearn.metrics import recall_score\n",
    "recall = recall_score(y_true, y_pred, average='macro')\n",
    "print(\"재현율 : \", recall)\n",
    "\n",
    "recall = recall_score(y_true_str, y_pred_str, average='macro')\n",
    "print(\"재현율 : \", recall)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7374e89b",
   "metadata": {},
   "source": [
    "### F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14be291",
   "metadata": {},
   "outputs": [],
   "source": [
    "# F1 Score\n",
    "from sklearn.metrics import f1_score\n",
    "F1 = f1_score(y_true, y_pred, average='macro')\n",
    "print(\"재현율 : \", F1)\n",
    "\n",
    "F1 = f1_score(y_true_str, y_pred_str, average='macro')\n",
    "print(\"재현율 : \", F1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
